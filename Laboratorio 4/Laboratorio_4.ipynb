{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_XcuC2rXQWb",
        "pycharm": {}
      },
      "source": [
        "# Laboratorio 4: Clasificación II (comparar clasifidores, selección de hipérparámetros, clases desbalanceadas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2HCI5sYtlJJ"
      },
      "source": [
        "# Declaración de compromiso ético\n",
        "\n",
        "\n",
        "Nosotros **AGREGUEN SUS NOMBRES COMPLETOS**, declaramos que realizamos de manera grupal los pasos de la presente actividad. También declaramos no incurrir en copia, ni compartir nuestras respuestas con otras personas ni con otros grupos. Por lo que, ratificamos que las respuestas son de nuestra propia confección y reflejan nuestro propio conocimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMUzxXj7XQWi",
        "pycharm": {}
      },
      "source": [
        "# Instrucciones\n",
        "\n",
        "\n",
        "1. Trabajen en equipos de dos personas. Salvo excepciones, no se corregirá entregas con menos de dos integrantes.\n",
        "\n",
        "2. Modifique este archivo `.ipynb` agregando sus respuestas donde corresponda.\n",
        "\n",
        "3. El formato de entrega para esta actividad es un archivo **html**. Genere un archivo HTML y súbalo a U-Cursos. Basta con que **uno de los integrantes haga la entrega**. Si ambos hacen una entrega en U-Cursos, se revisará cualquiera de éstas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zo8shEyQ3um"
      },
      "source": [
        "# Estructura del laboratorio\n",
        "\n",
        "Este laboratorio está conformado por preguntas teóricas de temas vistos en clases y preguntas prácticas (donde se requiere completar código) intercaladas con preguntas de interpretación de resultados y análisis. La parte práctica se divide en:\n",
        "\n",
        "1. Comparar clasificadores con ciertos *baselines* o clasificadores base.\n",
        "2. Seleccionar hiperparámetros.\n",
        "3. Trabajar con clases desbalanceadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9ohYCUFXADR"
      },
      "source": [
        "## Pregunta 1.1  \n",
        "\n",
        "Para realizar la evaluación de distintos clasificadores, vamos a crear la función `run_classifier()`, la cual evalúa un clasificador `clf` recibido como parámetro, un dataset `X,y` (features y target) y un número de tests llamado `num_test`. Esta función almacena y retorna los valores de precision, recall y f1-score en la variable `metrics` además de los resultados de predicción.\n",
        "\n",
        "En base a lo anterior, incluya las sentencias que ajusten el modelo junto a su correspondiente predicción sobre los datos. **No use cross-validation ni tampoco el parámetro `random_state`.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-28T01:11:34.028494Z",
          "start_time": "2020-09-28T01:11:34.018999Z"
        },
        "id": "TndzyqreXADS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "def run_classifier(clf, X, y, num_tests=100):\n",
        "    metrics = {'precision': [], 'recall': [], 'f1-score': []}\n",
        "\n",
        "    for _ in range(num_tests):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)\n",
        "        ### INICIO COMPLETAR ACÁ\n",
        "\n",
        "        #### TIP: entrene el modelo con los sets de entrenamientos, y\n",
        "        #### cree la variable predictions con las predicciones del conjunto de testing\n",
        "\n",
        "        # Entrenar modelo \n",
        "\n",
        "        predictions = clf.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "        ### FIN COMPLETAR ACÁ\n",
        "        # 0=Malignant, 1=Benign. In sklearn metrics, positive label is by default=1\n",
        "        #metrics['y_pred'] = predictions\n",
        "        metrics['precision'].append(precision_score(y_test, predictions, pos_label=0))\n",
        "        metrics['recall'].append(recall_score(y_test, predictions, pos_label=0))\n",
        "        metrics['f1-score'].append(f1_score(y_test, predictions, pos_label=0))\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjXFx9xIXADU"
      },
      "source": [
        "Luego de completar el código anterior, ejecute el siguiente bloque para comparar distintos clasificadores.\n",
        "Usaremos un **dataset de cáncer de mamas** para evaluar. La información del dataset se puede encontrar en el siguiente link: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-28T01:11:37.747387Z",
          "start_time": "2020-09-28T01:11:34.031505Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P2TfM7_XADU",
        "outputId": "4ef33798-a5d6-4674-8b5c-951346bd749c",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------\n",
            "Resultados para clasificador:  Base Dummy\n",
            "Precision promedio: 0.37186465572485905\n",
            "Recall promedio: 0.3716900186311729\n",
            "F1-score promedio: 0.3697714788796518\n",
            "----------------\n",
            "\n",
            "\n",
            "----------------\n",
            "Resultados para clasificador:  Decision Tree\n",
            "Precision promedio: 0.9086960189292944\n",
            "Recall promedio: 0.9016304302340054\n",
            "F1-score promedio: 0.9043150176723701\n",
            "----------------\n",
            "\n",
            "\n",
            "----------------\n",
            "Resultados para clasificador:  Gaussian Naive Bayes\n",
            "Precision promedio: 0.9381667007796242\n",
            "Recall promedio: 0.8931039044728963\n",
            "F1-score promedio: 0.9143283025568928\n",
            "----------------\n",
            "\n",
            "\n",
            "----------------\n",
            "Resultados para clasificador:  KNN\n",
            "Precision promedio: 0.9398739695930357\n",
            "Recall promedio: 0.8822293499262599\n",
            "F1-score promedio: 0.9095045153978848\n",
            "----------------\n",
            "\n",
            "\n",
            "----------------\n",
            "Resultados para clasificador:  Support Vector Machines\n",
            "Precision promedio: 0.9682960035171932\n",
            "Recall promedio: 0.7820968181280223\n",
            "F1-score promedio: 0.8639960245637066\n",
            "----------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## ejecutar este código\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB  # naive bayes\n",
        "from sklearn.neighbors import KNeighborsClassifier #kNN\n",
        "from sklearn.svm import SVC  # support vector machine\n",
        "\n",
        "bc = load_breast_cancer()    # dataset cancer de mamas\n",
        "X_bc = bc.data\n",
        "y_bc = bc.target\n",
        "\n",
        "c0 = (\"Base Dummy\", DummyClassifier(strategy='stratified'))\n",
        "c1 = (\"Decision Tree\", DecisionTreeClassifier(max_depth=5))\n",
        "c2 = (\"Gaussian Naive Bayes\", GaussianNB())\n",
        "c3 = (\"KNN\", KNeighborsClassifier(n_neighbors=10))\n",
        "c4 = (\"Support Vector Machines\", SVC())\n",
        "\n",
        "classifiers = [c0, c1, c2, c3, c4]\n",
        "\n",
        "results = {}\n",
        "for name, clf in classifiers:\n",
        "    metrics = run_classifier(clf, X_bc, y_bc)   # hay que implementarla en el bloque anterior.\n",
        "    results[name] = metrics\n",
        "    print(\"----------------\")\n",
        "    print(\"Resultados para clasificador: \", name)\n",
        "    print(\"Precision promedio:\", np.array(metrics['precision']).mean())\n",
        "    print(\"Recall promedio:\", np.array(metrics['recall']).mean())\n",
        "    print(\"F1-score promedio:\", np.array(metrics['f1-score']).mean())\n",
        "    print(\"----------------\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcdnXXH6XADX"
      },
      "source": [
        "## Pregunta 1.2\n",
        "\n",
        "Analizando los resultados obtenidos de cada clasificador, y basándose en las métricas calculadas. ¿Cuál es el mejor clasificador? ¿Qué métricas observó para tomar esa decisión y por qué? **considerando el problema que aborda**. Fundamente su respuesta.\n",
        "\n",
        "(Considere *malignant* como clase positiva, y *benign* como clase negativa.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4y5d8pjXADX"
      },
      "source": [
        "\n",
        "**Respuesta**:\n",
        "\n",
        "El mejor clasificador en base a los resultados tanto de recall como precisión es Naive Bayes, siendo aquel con F1-score más alto al querer comparar con otros métodos y realizar un trade off entre recall/precisión, en donde resulta ser un mejor método que KNN ya que gana más precisión de lo que se pierde en recall. \n",
        "\n",
        "Las métricas observadas fueron F1-score para el trade off entre métodos con precisión y recall similares entre sí pero con leves diferencuas (Naive Bayes, KNN, Decision Tree). Por otra parte, se analizo que si bien SVM tiene una precisión muy alta, su recall tiene un 20% de casos en los que no le indica a alguien con cancer de mama que su cancer es maligno, siendo descartado por ello, analogamente, Base Dummy fue descartado ya que posee una baja precision y recall, dando lugar a una gran cantidad de casos de falsos positivos y falsos negativos de cancer de mama.\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1Foz8AYvoCG"
      },
      "source": [
        "## Pregunta 1.3\n",
        "\n",
        "¿Cuál sería la razón de maximizar la métrica 'recall' en el problema abordado?\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-28T00:01:32.541764Z",
          "start_time": "2020-09-28T00:01:32.538758Z"
        },
        "id": "dcgTjBD7XADZ"
      },
      "source": [
        "# Parte 2: Seleccionar hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0zWKX6Yuwcd"
      },
      "source": [
        "Los hiperparámetros son parámetros que no se aprenden directamente dentro de los estimadores. En scikit-learn se pasan como argumentos al constructor de las clases, por ejemplo, cuál kernel usar para Support Vector Classifier, o qué criterio para Decision Tree, etc. Es posible y recomendable buscar en el espacio de hiperparámetros la mejor alternativa.\n",
        "\n",
        "Tenga en cuenta que es común que un pequeño subconjunto de esos parámetros pueda tener un gran impacto en el rendimiento predictivo o de cálculo del modelo, mientras que otros pueden dejar sus valores predeterminados. Se recomienda leer la documentación de la clase de estimador para obtener una mejor comprensión de su comportamiento esperado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p7LwuvEXADa"
      },
      "source": [
        "**Dataset:** En esta y la siguiente parte del laboratorio utilizaremos el dataset **\"ML Classification: Predicting 5-Year Career Longevity for NBA Rookies\"** de data.world (https://data.world/ssaudz/ml-classification-predicting-5-year-career-longevity-for-nb). Este dataset contiene estadísticas de los novatos en la NBA y busca predecir si un jugador podrá durar 5 años en la liga. La columna objetivo es *TARGET_5Yrs*. Esta es una versión preprocesada del dataset original (después de eliminar registros duplicados por nombre del jugador, anonimizar los datos, y eliminar los registros con valores nulos)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmYdG7xNtlJT",
        "outputId": "109ed810-a9af-4eb1-fdb5-626a2aac5e62",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1284, 20)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/cinthiasanchez/data-mining/main/NBA_career_longevity.csv')\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "4U7AyfNCtlJT",
        "outputId": "1626abed-def0-4b2d-95ca-2c7000096d9f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GP</th>\n",
              "      <th>MIN</th>\n",
              "      <th>PTS</th>\n",
              "      <th>FGM</th>\n",
              "      <th>FGA</th>\n",
              "      <th>FG%</th>\n",
              "      <th>3P Made</th>\n",
              "      <th>3PA</th>\n",
              "      <th>3P%</th>\n",
              "      <th>FTM</th>\n",
              "      <th>FTA</th>\n",
              "      <th>FT%</th>\n",
              "      <th>OREB</th>\n",
              "      <th>DREB</th>\n",
              "      <th>REB</th>\n",
              "      <th>AST</th>\n",
              "      <th>STL</th>\n",
              "      <th>BLK</th>\n",
              "      <th>TOV</th>\n",
              "      <th>TARGET_5Yrs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36</td>\n",
              "      <td>27.4</td>\n",
              "      <td>7.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>7.6</td>\n",
              "      <td>34.7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.1</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>2.3</td>\n",
              "      <td>69.9</td>\n",
              "      <td>0.7</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>26.9</td>\n",
              "      <td>7.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>29.6</td>\n",
              "      <td>0.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>23.5</td>\n",
              "      <td>2.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>76.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   GP   MIN  PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
              "0  36  27.4  7.4  2.6  7.6  34.7      0.5  2.1  25.0  1.6  2.3  69.9   0.7   \n",
              "1  35  26.9  7.2  2.0  6.7  29.6      0.7  2.8  23.5  2.6  3.4  76.5   0.5   \n",
              "\n",
              "   DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
              "0   3.4  4.1  1.9  0.4  0.4  1.3            0  \n",
              "1   2.0  2.4  3.7  1.1  0.5  1.6            0  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "G1KJep_YtlJU"
      },
      "outputs": [],
      "source": [
        "#separando atributos predictivos (X) del atributo objetivo (y)\n",
        "X = data.iloc[:,:-1].values\n",
        "y = data['TARGET_5Yrs'].values\n",
        "\n",
        "#dividiendo los datos de entrenamiento y validación\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30,\n",
        "                                                    random_state=15, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XnXy9a7XADa"
      },
      "source": [
        "## GridSearchCV\n",
        "\n",
        "Una alternativa para seleccionar hiperparámetros es GridSearchCV, la cual considera exhaustivamente todas las combinaciones de parámetros. GridSearchCV recibe un `estimador`, `param_grid` (un diccionario o una lista de diccionarios con los nombres de los parámetros a probar como keys y una lista de los valores a probar), `scoring` una o varias funciones de puntuación (score) para evaluar cada combinación de parámetros (opciones válidas: https://scikit-learn.org/stable/modules/model_evaluation.html), y `cv` una extrategia para hacer validación cruzada.\n",
        "\n",
        "El siguiente código muestra cómo seleccionar el número de vecinos y qué pesos otorgar a los vecinos en un clasificador KNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-28T01:11:38.025125Z",
          "start_time": "2020-09-28T01:11:37.749394Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlzgox92XADb",
        "outputId": "e84ff949-37d2-4fe2-86f6-af59cb86c2a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor combinación de parámetros:\n",
            "{'n_neighbors': 10, 'weights': 'uniform'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.60      0.62       145\n",
            "           1       0.77      0.80      0.78       241\n",
            "\n",
            "    accuracy                           0.73       386\n",
            "   macro avg       0.71      0.70      0.70       386\n",
            "weighted avg       0.72      0.73      0.72       386\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Definimos una semilla para que los resultados sean reproducibles\n",
        "np.random.seed(42)\n",
        "\n",
        "#Configure tuned_parameters\n",
        "tuned_parameters = {'n_neighbors': [1, 3, 5, 10],\n",
        "                    'weights': ['uniform','distance']}\n",
        "\n",
        "#set scoring metric\n",
        "score = 'precision'\n",
        "\n",
        "#Construir el clf con GridSearch\n",
        "clf = GridSearchCV(\n",
        "    KNeighborsClassifier(),\n",
        "    param_grid=tuned_parameters,\n",
        "    cv=5,\n",
        "    scoring=score\n",
        ")\n",
        "\n",
        "#Entrenar clf\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Mejor combinación de parámetros:\")\n",
        "print(clf.best_params_)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX8g3y2zXADd"
      },
      "source": [
        "## Pregunta 2.1\n",
        "\n",
        "*  a) Utilizando los datos del bloque anterior (NBA_career_longevity.csv), realice este mismo proceso para un clasificador `DecisionTree` y los parametros `criterion=['gini','entropy']`, `max_depth=[3,5,7,10]` y tomando como `scoring` metric `'f1'`. Use `cv=10`.\n",
        "*  b) ¿Qué puede decir de los resultados, con cuáles parámetros los obtuvo (revise que su respuesta concuerde con los resultados que imprime)? ¿Cuál considera que es la principal ventaja de aplicar GridSearchCV? ¿Considera que es necesario seguir explorando los parámetros?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta de b)**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-28T01:11:38.300858Z",
          "start_time": "2020-09-28T01:11:38.027133Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSmxont4XADd",
        "outputId": "664bf8ca-ed85-4b48-f94f-bad73678a897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor combinación de parámetros:\n",
            "{'criterion': 'gini', 'max_depth': 3}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.59      0.61       145\n",
            "           1       0.76      0.78      0.77       241\n",
            "\n",
            "    accuracy                           0.71       386\n",
            "   macro avg       0.69      0.69      0.69       386\n",
            "weighted avg       0.71      0.71      0.71       386\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## RESPUESTA A PREGUNTA 2.1 a)\n",
        "\n",
        "### INICIO COMPLETAR ACÁ\n",
        "\n",
        "# Definimos una semilla para que los resultados sean reproducibles\n",
        "np.random.seed(39)\n",
        "\n",
        "#Configure tuned_parameters\n",
        "\n",
        "tuned_parameters = {'criterion': ['gini', 'entropy'],\n",
        "                     'max_depth': [3, 5, 7, 10]}\n",
        "\n",
        "#set scoring metric\n",
        "score = 'f1'\n",
        "\n",
        "#Construir el clf con GridSearch\n",
        "clf = GridSearchCV(\n",
        "    DecisionTreeClassifier(),\n",
        "    param_grid=tuned_parameters,\n",
        "    cv=10,\n",
        "    scoring=score\n",
        ")\n",
        "\n",
        "#Entrenar clf\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Recuerde definir una semilla para que los resultados sean reproducibles\n",
        "# Use su número favorito como semilla\n",
        "\n",
        "### FIN COMPLETAR ACÁ\n",
        "\n",
        "print(\"Mejor combinación de parámetros:\")\n",
        "print(clf.best_params_)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Respuesta:*\n",
        "\n",
        "Para los parametros definidos, la acurracy da un valor bueno, pero no deseable ya que deja una gran margen de error, es por esto que lo óptimo seria seguir explorando los parámetros o incluso volver al dataset para entender mejor como mejorar el modelo. \n",
        "\n",
        "La ventaja de GridSearchCV es que permite obtener los mejores parametros a utilizar mediante una busqueda exhaustiva, mejorando la eficiencia del analisis, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf4BSIjTXADq"
      },
      "source": [
        "# Parte 3: Trabajar con clases desbalanceadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3fb8kQ7XADq"
      },
      "source": [
        "Al explorar el dataset anterior, se nota un desbalance importante (38%-62%). Para mejorar el rendimiento de un clasificador sobre clases desbalanceadas existen varias técnicas. En esta parte, veremos cómo tratar con este problema usando (sub/over) sampling de las clases.\n",
        "\n",
        "(*Nota: Para ejecutar el siguiente bloque es necesaria la librería `pandas` que viene incluida en Anaconda.*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-28T00:36:22.116129Z",
          "start_time": "2020-09-28T00:36:22.111116Z"
        },
        "id": "QFNMUPd-XADu"
      },
      "source": [
        "Note el desbalance de las clases ejecutando el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-28T01:11:38.476062Z",
          "start_time": "2020-09-28T01:11:38.467038Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXrcsboyXADu",
        "outputId": "0131b106-e56a-4882-b23d-0db65aaf66b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribucion de clases original\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TARGET_5Yrs\n",
              "1    802\n",
              "0    482\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Distribucion de clases original\")\n",
        "data['TARGET_5Yrs'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlMr6-9GXADx"
      },
      "source": [
        "Antes de hacer algo para tratar el desbalance entre las clases primero debemos dividir en train-test. Como ya hicimos la partición de train y test, vamos a explorarla a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-28T01:11:38.496117Z",
          "start_time": "2020-09-28T01:11:38.478068Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr7JzTG-XADy",
        "outputId": "49dbb6e1-2032-4c46-abcb-597d2fce6a1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de instancias por clase en el train:\n",
            "Clase 1: 561\n",
            "Clase 0: 337\n"
          ]
        }
      ],
      "source": [
        "#Dividmos igual que arriba.\n",
        "#Para facilitar el balance manual, X contendrá el dataset completo, pero luego eliminaremos de este el atributo objetivo.\n",
        "\n",
        "data_train, data_test, ytrain, ytest = train_test_split(data, data['TARGET_5Yrs'], test_size=.30,\n",
        "                                                random_state=15, stratify=data['TARGET_5Yrs'])\n",
        "\n",
        "print(\"Cantidad de instancias por clase en el train:\")\n",
        "print(\"Clase 1: \" + str((ytrain==1).sum()))\n",
        "print(\"Clase 0: \" + str((ytrain==0).sum()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_X5CY14XAD3"
      },
      "source": [
        "Aplicaremos **oversampling** y **subsampling** al train para que queden balanceados. Ejecute el siguiente código y note ahora que las clases están balanceadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-28T01:11:38.534218Z",
          "start_time": "2020-09-28T01:11:38.510154Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpXH_EZkXAD4",
        "outputId": "3049ba4e-6865-4cee-c042-4a04d6039957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribución de clases usando (over/sub) sampling: \n",
            "\n",
            "Data oversampled on class '0'\n",
            "TARGET_5Yrs\n",
            "1    561\n",
            "0    561\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Data subsampled on class '1'\n",
            "TARGET_5Yrs\n",
            "1    337\n",
            "0    337\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Distribución de clases usando (over/sub) sampling: \\n\")\n",
        "data_train = data_train.reset_index(drop=True)\n",
        "\n",
        "# oversampling sobre la clase 0\n",
        "idx = np.random.choice(data_train[data_train['TARGET_5Yrs'] == 0].index, size=224)\n",
        "data_oversampled = pd.concat([data_train, data_train.iloc[idx]])\n",
        "print(\"Data oversampled on class '0'\")\n",
        "print(data_oversampled['TARGET_5Yrs'].value_counts())\n",
        "print()\n",
        "\n",
        "\n",
        "# subsampling sobre la clase 1\n",
        "idx = np.random.choice(data_train.loc[data_train.TARGET_5Yrs == 1].index, size=224, replace=False)\n",
        "data_subsampled = data_train.drop(data_train.iloc[idx].index)\n",
        "print(\"Data subsampled on class '1'\")\n",
        "print(data_subsampled['TARGET_5Yrs'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urh4G7FhXAD6"
      },
      "source": [
        "**Nota:** *Librerías como `imblearn` son muy útiles para balancear los datos.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNRoMB4bXAD6"
      },
      "source": [
        "## Pregunta 3. 1\n",
        "\n",
        "¿Por qué aplicar subsampling/oversampling de las clases sobre el conjunto de entrenamiento en lugar de aplicarlo sobre el dataset completo? Argumente su respuesta.\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "Al realizar subsampling/oversampling en el dataset completo ocurre que por ejemplo se crean instancias que no existen y que pueden estar mal (por ejemplo un gato que vuela) o se pueden eliminar instancias correctas (un gato que maulla), afectanto así a los datos de testing.\n",
        "\n",
        "Además, una de las finalidades de realizar subsampling/oversampling es que se normalice la cantidad de datos o las probabilidades si se usa Naive Bayes para el dataset de training, con la finalidad de que permita mejorar el modelo en el proceso de clasificación.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Mich8PsMQ3uw"
      },
      "outputs": [],
      "source": [
        "## ejecutar este código para preparar los datos\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Preparando los data frames para ser compatibles con sklearn\n",
        "\n",
        "# datos test (mismo para todos los conjuntos de entrenamiento)\n",
        "X_test = data_test[data_train.columns[:-1]] # todo hasta la penultima columna\n",
        "y_test = data_test[data_train.columns[-1]]  # la última columna\n",
        "\n",
        "# datos entrenamiento \"originales\"\n",
        "X_orig = data_train[data_train.columns[:-1]]\n",
        "y_orig = data_train[data_train.columns[-1]]\n",
        "\n",
        "# datos entrenamiento \"oversampleados\"\n",
        "X_over = data_oversampled[data_train.columns[:-1]]\n",
        "y_over = data_oversampled[data_train.columns[-1]]\n",
        "\n",
        "# datos entrenamiento \"subsampleados\"\n",
        "X_subs = data_subsampled[data_train.columns[:-1]]\n",
        "y_subs = data_subsampled[data_train.columns[-1]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWA7_lHxXAD7"
      },
      "source": [
        "## Pregunta 3.2\n",
        "\n",
        "Complete el código necesario para entrenar un clasificador DecisionTree en cada uno de los tres casos (**original**, con **oversampling** y con **subsampling**) y luego compare los resultados sobre el conjunto de test (este es el mismo para los tres casos) obtenido con train_test_split sobre los datos originales. Muestre Precision, Recall y F1-score.\n",
        "\n",
        "Emplee como datos de entrada lo del bloque anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-28T01:11:38.601396Z",
          "start_time": "2020-09-28T01:11:38.553269Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXu3Hx77XAD9",
        "outputId": "b945c94d-06de-4fa8-f1d7-a23e68dc7133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ORIGINAL::::::::::\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.48      0.50       145\n",
            "           1       0.70      0.73      0.72       241\n",
            "\n",
            "    accuracy                           0.64       386\n",
            "   macro avg       0.61      0.61      0.61       386\n",
            "weighted avg       0.63      0.64      0.64       386\n",
            "\n",
            "SUBSAMPLED::::::::::\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.66      0.57       145\n",
            "           1       0.75      0.61      0.67       241\n",
            "\n",
            "    accuracy                           0.63       386\n",
            "   macro avg       0.63      0.63      0.62       386\n",
            "weighted avg       0.66      0.63      0.63       386\n",
            "\n",
            "OVERSAMPLED::::::::::\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.52      0.52       145\n",
            "           1       0.71      0.71      0.71       241\n",
            "\n",
            "    accuracy                           0.64       386\n",
            "   macro avg       0.62      0.62      0.62       386\n",
            "weighted avg       0.64      0.64      0.64       386\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Pasos:\n",
        "##  - instanciar el clasificador con DecisionTreeClassifier()\n",
        "##  - entrenar con fit()\n",
        "##  - hacer las predicciones\n",
        "##  - mostrar precision, recall y f1-score con classification report.\n",
        "\n",
        "# Fijar con random state\n",
        "\n",
        "print(\"ORIGINAL::::::::::\")\n",
        "clf_orig = DecisionTreeClassifier()\n",
        "clf_orig.fit(X_orig, y_orig)\n",
        "pred_orig = clf_orig.predict(X_test)\n",
        "print(classification_report(y_test, pred_orig))\n",
        "\n",
        "### INICIO COMPLETAR ACÁ\n",
        "\n",
        "print(\"SUBSAMPLED::::::::::\")\n",
        "clf_subs = DecisionTreeClassifier()\n",
        "clf_subs.fit(X_subs, y_subs)\n",
        "pred_subs = clf_subs.predict(X_test)\n",
        "print(classification_report(y_test, pred_subs))\n",
        "\n",
        "print(\"OVERSAMPLED::::::::::\")\n",
        "clf_over = DecisionTreeClassifier()\n",
        "clf_over.fit(X_over, y_over)\n",
        "pred_over = clf_over.predict(X_test)\n",
        "print(classification_report(y_test, pred_over))\n",
        "\n",
        "\n",
        "### FIN COMPLETAR ACÁ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XkE5zruXAD-"
      },
      "source": [
        "## Pregunta 3.3\n",
        "\n",
        "- Observe los resultados obtenidos por clase con cada conjunto de entrenamiento, ¿se puede observar alguna diferencia importante?\n",
        "- Indique una desventaja de usar oversampling y una desventaja de usar subsampling en clasificación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT_8XDc6XAD-"
      },
      "source": [
        "**Respuesta**: \n",
        "Para cada métrica podemos realizar las siguientes observaciones:\n",
        "F1 Score clase 0: Original < Oversampling < Subsampling\n",
        "F1 Score clase 1: Subsampling < Oversampling < Original\n",
        "\n",
        "accuracy: Subsampling < Original = Oversampling (no hay mucha diferencia entre conjuntos)\n",
        "precision clase 0: Subsampling < Original = Oversampling\n",
        "precision clase 1: Original < Oversampling < Subsampling\n",
        "\n",
        "macro precision: Original < Oversampling < Subsampling\n",
        "macro recall: Original < Oversampling < Subsampling\n",
        "macro f1-score: Original < Oversampling < Subsampling\n",
        "\n",
        "weight f1-score: Subsampling < Original = Oversampling\n",
        "\n",
        "Si bien se obtuvieron diferencias, estas son muy leves, y pueden variar dependiendo de la ejecución, el cambio más notable se puede apreciar mediante f1-score por clase, en donde para clase=0 es mejor realizar Subsampling, mientras que para la clase=1 es mejor mantener la data original a fin de obtener el mejor modelo.\n",
        "\n",
        "Por otra parte es interesante notar que para cada conjunto los valores de precision, recall y f1-score son equivalentes respectivamente, y que de igual forma el f1-score para weighted avg es equivalente a la accuracy en cada conjunto.\n",
        "\n",
        "Una desventaja de usar oversampling es que al crear datos artificiales en base a los originales, se corre el riesgo de provocar overfitting y que el modelo pierda la capacidad de generalizar.\n",
        "\n",
        "Una desventaja de usar subsampling es la pérdidad de instancias capaces de brindar variedad de muestras a la clase, lo que generaría que se pierda la capacidad de clasificar correctamente una instancia I perteneciente a la clase C ya que no se ha entrenado el modelo con instancias similares a la I para dicha clase C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s5HxlPctlJZ"
      },
      "source": [
        "## Pregunta 3.4\n",
        "\n",
        "Compare los resultados del caso **ORIGINAL** (donde el clasificador usa los parámetros por defecto DecisionTreeClassifier()) versus el resultado de la pregunta 2.1 donde usa los mejores parámetros con GridSearchCV. ¿Qué opina de los resultados?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk2peTlatlJZ"
      },
      "source": [
        "**Respuesta**:\n",
        "\n",
        "ORIGINAL::::::::::\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.52      0.48      0.50       145\n",
        "           1       0.70      0.73      0.72       241\n",
        "\n",
        "    accuracy                           0.64       386\n",
        "   macro avg       0.61      0.61      0.61       386\n",
        "weighted avg       0.63      0.64      0.64       386\n",
        "\n",
        "\n",
        "Mejor combinación de parámetros:\n",
        "{'criterion': 'gini', 'max_depth': 3}\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.62      0.59      0.61       145\n",
        "           1       0.76      0.78      0.77       241\n",
        "\n",
        "    accuracy                           0.71       386\n",
        "   macro avg       0.69      0.69      0.69       386\n",
        "weighted avg       0.71      0.71      0.71       386\n",
        "\n",
        "\n",
        "Se observa que para las clases las medidas de precision, recall y f1-score son notablemente mejores para GridSearchCV, lo cual se ve reflejado en que el resultado de la Pregunta 2.1 tiene mayor accuracy que el caso 'Original'. Abordando macro avg notamos que nuevamente se cumple que los valores obtenidos son mejores en el caso de GridSearchCV e igualmente para weighted avg. Por lo tanto la conclusión es que es mucho mejor optar por las indicaciones obtenidas al usar este método."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Eso es todo! Que tengan buena semana!! :))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![footer](https://miro.medium.com/v2/resize:fit:828/format:webp/1*8jAT7ocXcZTw5TcyiUiNIA.jpeg)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
